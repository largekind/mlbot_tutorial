{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f2cc25f-6603-4846-8e2f-8269cd34ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       timestamp        open        high         low       close        volume\n",
      "0     2017-10-31   679910.34   727288.22   674553.25   723579.09  4.728300e+10\n",
      "1     2017-11-01   723751.37   766552.45   713575.88   764334.90  5.844858e+10\n",
      "2     2017-11-02   764247.87   857528.51   761617.11   805165.37  9.242606e+10\n",
      "3     2017-11-03   805246.62   853429.62   786480.90   823854.18  8.196366e+10\n",
      "4     2017-11-04   823851.31   845389.80   800200.82   839556.37  6.597304e+10\n",
      "...          ...         ...         ...         ...         ...           ...\n",
      "1996  2023-04-19  4069137.27  4076795.31  3872362.29  3893088.33  2.048354e+10\n",
      "1997  2023-04-20  3893088.33  3918645.83  3765607.66  3786412.95  1.844144e+10\n",
      "1998  2023-04-21  3786412.95  3802188.72  3644461.28  3654750.87  1.702854e+10\n",
      "1999  2023-04-22  3654750.87  3754880.86  3641006.51  3747411.86  8.716559e+09\n",
      "2000  2023-04-23  3747411.86  3747981.50  3700333.12  3709590.27  3.535152e+09\n",
      "\n",
      "[2001 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def fetch_cryptocompare_ohlcv_data(fsym, tsym, limit=2000, aggregate=1, interval='day'):\n",
    "    \"\"\"\n",
    "    Cryptocompare APIを使用して、過去のOHLCVデータを取得する関数\n",
    "    \"\"\"\n",
    "    base_url = 'https://min-api.cryptocompare.com/data/v2/histo'\n",
    "    intervals = {'minute': 'minute', 'hour': 'hour', 'day': 'day'}\n",
    "    \n",
    "    if interval not in intervals:\n",
    "        raise ValueError(f\"Invalid interval: {interval}\")\n",
    "\n",
    "    url = f\"{base_url}{intervals[interval]}\"\n",
    "    params = {\n",
    "        'fsym': fsym.upper(),\n",
    "        'tsym': tsym.upper(),\n",
    "        'limit': limit,\n",
    "        'aggregate': aggregate\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()['Data']['Data']\n",
    "    \n",
    "    # データをpandas DataFrameに変換\n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volumeto']]\n",
    "    df.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def load_from_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "filename = 'ohlcv_data.csv'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    # ローカルにファイルが存在する場合、データをローカルから読み込む\n",
    "    ohlcv_data = load_from_csv(filename)\n",
    "else:\n",
    "    # ローカルにファイルが存在しない場合、データを取得し、ローカルに保存する\n",
    "    fsym = 'BTC'\n",
    "    tsym = 'JPY'\n",
    "    ohlcv_data = fetch_cryptocompare_ohlcv_data(fsym, tsym)\n",
    "    save_to_csv(ohlcv_data, filename)\n",
    "\n",
    "print(ohlcv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33ebe2a2-3107-4502-9fcd-94042d13b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"positional_encodings\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encodings[:, :x.size(1), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6c8a082-3476-4064-86ab-137f46e1b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, Loss: 0.067143\n",
      "Epoch 1/10, Loss: 0.015088\n",
      "Epoch 2/10, Loss: 0.009877\n",
      "Epoch 3/10, Loss: 0.005192\n",
      "Epoch 4/10, Loss: 0.003849\n",
      "Epoch 5/10, Loss: 0.002649\n",
      "Epoch 6/10, Loss: 0.002885\n",
      "Epoch 7/10, Loss: 0.002646\n",
      "Epoch 8/10, Loss: 0.002242\n",
      "Epoch 9/10, Loss: 0.001800\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 398 and the array at index 1 has size 17910",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_134/398557101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_134/398557101.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# スケーラを使って価格に戻す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mclose_col_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mpredictions_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_col_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclose_col_index\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_col_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# 予測結果の表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 398 and the array at index 1 has size 17910"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, seq_length, n_heads, n_encoder_layers, n_decoder_layers, d_model, d_ff):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, seq_length)\n",
    "        self.transformer = nn.Transformer(d_model, n_heads, n_encoder_layers, n_decoder_layers, d_ff)\n",
    "        self.fc = nn.Linear(d_model, input_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoding(src)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
    "        tgt = self.pos_encoding(tgt)\n",
    "        output = self.transformer(src, tgt)\n",
    "        return self.fc(output)\n",
    "\n",
    "def load_data(df):\n",
    "    feature_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    input_data = df[feature_cols].values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    input_data = scaler.fit_transform(input_data)\n",
    "\n",
    "    return input_data, scaler\n",
    "\n",
    "def create_dataset(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x.append(data[i : i + seq_length, :])\n",
    "        y.append(data[i + 1 : i + seq_length + 1, :])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def main():\n",
    "    window_size = 10\n",
    "    batch_size = 32\n",
    "    n_epochs = 10\n",
    "\n",
    "    # データの取得と前処理\n",
    "    input_data, scaler = load_data(ohlcv_data)\n",
    "    X, y = create_dataset(input_data, window_size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    # テンソルに変換\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # モデルの作成\n",
    "    input_dim = 5\n",
    "    seq_length = window_size\n",
    "    n_heads = 2\n",
    "    n_encoder_layers = 3\n",
    "    n_decoder_layers = 3\n",
    "    d_model = 128\n",
    "    d_ff = 256\n",
    "    model = TransformerModel(input_dim, seq_length, n_heads, n_encoder_layers, n_decoder_layers, d_model, d_ff)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 学習\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_x, batch_y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # トランスフォーマーモデル用の入力とターゲットシーケンスを準備\n",
    "            src = batch_x[:, :-1, :]\n",
    "            tgt = batch_y[:, :-1, :]\n",
    "        \n",
    "            # 入力とターゲットのシーケンスをモデルに渡す\n",
    "            output = model(src, tgt)\n",
    "\n",
    "            loss = criterion(output, tgt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch}/{n_epochs}, Loss: {loss:.6f}\")\n",
    "\n",
    "    # 予測\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        src = X_test_tensor[i:i + 1, :-1, :]\n",
    "        tgt = X_test_tensor[i:i + 1, 1:, :]\n",
    "        prediction = model(src, tgt).detach().numpy()\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    # スケーラを使って価格に戻す\n",
    "    close_col_index = 3\n",
    "    predictions_rescaled = scaler.inverse_transform(np.hstack([np.zeros((len(predictions), close_col_index)), predictions.reshape(-1, 1), np.zeros((len(predictions), input_data.shape[1] - close_col_index - 1))]))[:, close_col_index]\n",
    "\n",
    "    # 予測結果の表示\n",
    "    for i, pred in enumerate(predictions_rescaled):\n",
    "        print(f\"Predicted close price for day {i + 1}: {pred}, Actual close price: {scaler.inverse_transform(y_test[i].reshape(1, -1))[0][3]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b08cd5-8ce3-4db1-9639-c15a08fe25f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
